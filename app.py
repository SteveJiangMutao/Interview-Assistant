import streamlit as st
import google.generativeai as genai
import tempfile
import os
import time
import json
from docx import Document
from docx.shared import Pt, RGBColor, Inches, Cm
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING, WD_TAB_ALIGNMENT
from docx.oxml.ns import qn
import io
import datetime
from google.api_core import retry

# --- ğŸ”§ é…ç½®é¡¹ï¼šLogo æ–‡ä»¶ ---
LOGO_PATH = "logo.png" 

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Clearstate Interview System",
    layout="wide",
    page_icon="ğŸ§¬",
    initial_sidebar_state="expanded"
)

# --- CSS æ ·å¼ ---
st.markdown("""
<style>
    .main-header { font-size: 2.0rem; color: #2c3e50; font-weight: bold; margin-bottom: 5px; }
    .sub-header { font-size: 1.0rem; color: #7f8c8d; margin-bottom: 20px; }
    .developer-credit { font-size: 0.85rem; color: #95a5a6; margin-top: 50px; border-top: 1px solid #bdc3c7; padding-top: 10px; }
    div[data-testid="stFileUploader"] { margin-top: 20px; }
</style>
""", unsafe_allow_html=True)

# --- Session State ---
if 'analysis_result' not in st.session_state:
    st.session_state['analysis_result'] = None

# --- ğŸ§¹ æ–‡æœ¬æ¸…æ´—å‡½æ•° ---
def clean_text(text):
    """å»é™¤ Markdown ç¬¦å·ï¼Œä¿æŒæ–‡æœ¬çº¯å‡€"""
    if isinstance(text, str):
        text = text.replace("**", "").replace("__", "")
        text = text.replace("##", "").replace("###", "")
        return text.strip()
    return text

# --- Word æ ¼å¼åŒ–è¾…åŠ©å‡½æ•° ---
def set_font_style(run, font_size=11, bold=False):
    run.font.name = 'Times New Roman'
    run.element.rPr.rFonts.set(qn('w:eastAsia'), 'å¾®è½¯é›…é»‘')
    run.font.size = Pt(font_size)
    run.font.color.rgb = RGBColor(0, 0, 0)
    run.bold = bold

def add_styled_paragraph(doc, text, bold=False, size=11, is_bullet=False):
    clean_content = clean_text(str(text))
    p = doc.add_paragraph()
    p.paragraph_format.line_spacing = 1.0
    p.paragraph_format.space_before = Pt(3)
    p.paragraph_format.space_after = Pt(3)
    p.alignment = WD_ALIGN_PARAGRAPH.LEFT 
    
    # --- æ‚¬æŒ‚ç¼©è¿›é€»è¾‘ (Strict Hanging Indent) ---
    if is_bullet:
        indent_size = Inches(0.25)
        p.paragraph_format.left_indent = indent_size
        p.paragraph_format.first_line_indent = -indent_size
        p.paragraph_format.tab_stops.add_tab_stop(indent_size, WD_TAB_ALIGNMENT.LEFT)
        
        final_text = f"â€¢\t{clean_content}"
        run = p.add_run(final_text)
    else:
        run = p.add_run(clean_content)
    
    set_font_style(run, font_size=size, bold=bold)
    return p

# --- ğŸŒ æ ‡é¢˜æ˜ å°„å­—å…¸ ---
SECTION_HEADERS = {
    "commercial": {
        "zh": {
            "market_size": "1. å¸‚åœºè§„æ¨¡ä¸ä½“é‡",
            "competition": "2. ç«äº‰æ ¼å±€",
            "sales_marketing": "3. é”€å”®ä¸è¥é”€ç­–ç•¥",
            "channel_access": "4. æ¸ é“ä¸å‡†å…¥",
            "trends": "5. è¡Œä¸šè¶‹åŠ¿"
        },
        "en": {
            "market_size": "1. Market Size & Scale",
            "competition": "2. Competition Landscape",
            "sales_marketing": "3. Sales & Marketing Strategy",
            "channel_access": "4. Channel & Access Strategy",
            "trends": "5. Industry Trends"
        }
    },
    "clinical": {
        "zh": {
            "clinical_value": "1. ä¸´åºŠä»·å€¼ä¸ç–—æ•ˆ",
            "adoption": "2. ä¸´åºŠåº”ç”¨ä¸æœ¯å¼",
            "competition": "3. ç«å“å¯¹æ¯”",
            "pain_points": "4. æœªæ»¡è¶³éœ€æ±‚ä¸ç—›ç‚¹",
            "expectations": "5. æœªæ¥é¢„æœŸ"
        },
        "en": {
            "clinical_value": "1. Clinical Value & Efficacy",
            "adoption": "2. Adoption & Usage",
            "competition": "3. Competitive Comparison",
            "pain_points": "4. Unmet Needs & Pain Points",
            "expectations": "5. Future Expectations"
        }
    },
    "meeting": {
        "zh": {
            "meeting_context": "1. ä¼šè®®èƒŒæ™¯ä¸å‚ä¼šäºº",
            "key_discussion": "2. æ ¸å¿ƒè®¨è®ºå†…å®¹",
            "conclusions": "3. ç»“è®ºä¸å†³ç­–",
            "action_items": "4. å¾…åŠäº‹é¡¹ä¸ä¸‹ä¸€æ­¥ (Follow-up)"
        },
        "en": {
            "meeting_context": "1. Context & Attendees",
            "key_discussion": "2. Key Discussion Points",
            "conclusions": "3. Conclusions & Decisions",
            "action_items": "4. Action Items & Follow-ups"
        }
    }
}

# --- Word ç”Ÿæˆé€»è¾‘ ---
def generate_word_report(data, company, product, date, mode):
    doc = Document()
    
    # 0. Logo (å³ä¸Šè§’, é«˜åº¦ 0.65cm)
    section = doc.sections[0]
    header = section.header
    p_header = header.paragraphs[0]
    p_header.alignment = WD_ALIGN_PARAGRAPH.RIGHT
    
    if os.path.exists(LOGO_PATH):
        try:
            run_header = p_header.add_run()
            run_header.add_picture(LOGO_PATH, height=Cm(0.65))
        except Exception as e:
            print(f"Logo Error: {e}")
    
    # è¯­è¨€åˆ¤æ–­
    lang = data.get('language', 'en')
    if 'zh' in lang.lower() or 'chinese' in lang.lower() or 'cn' in lang.lower():
        lang_code = 'zh'
    else:
        lang_code = 'en'

    # 1. æ ‡é¢˜ä¸åŸºç¡€ä¿¡æ¯
    if lang_code == 'zh':
        if mode == 'meeting':
            title_text = f"{company} - {product} ä¼šè®®çºªè¦"
            type_text = 'å†…éƒ¨ä¼šè®®/å¤–éƒ¨æ²Ÿé€š'
        else:
            title_text = f"{company} - {product} è®¿è°ˆè®°å½•"
            type_text = 'å•†ä¸š/å‚å•†' if mode == 'commercial' else 'ä¸´åºŠ/ä¸“å®¶'
            
        date_prefix = "æ—¥æœŸ"
        type_prefix = "ç±»å‹"
        exec_title = "1. æ‘˜è¦æ¦‚è§ˆ" if mode == 'meeting' else "1. æ‰§è¡Œæ‘˜è¦"
        other_title = "5. å…¶ä»–è¡¥å……" if mode == 'meeting' else "3. å…¶ä»–å‘ç°"
    else:
        if mode == 'meeting':
            title_text = f"{company} - {product} Meeting Minutes"
            type_text = 'Meeting/Discussion'
        else:
            title_text = f"{company} - {product} Interview Record"
            type_text = 'Trade' if mode == 'commercial' else 'Clinical/Expert'
            
        date_prefix = "Date"
        type_prefix = "Type"
        exec_title = "1. Executive Summary"
        other_title = "3. Other Findings"

    p_title = doc.add_paragraph()
    p_title.alignment = WD_ALIGN_PARAGRAPH.LEFT
    p_title.paragraph_format.space_after = Pt(12)
    run_title = p_title.add_run(title_text)
    set_font_style(run_title, font_size=16, bold=True)
    
    # Meta Info
    info_text = f"{date_prefix}: {date} | {type_prefix}: {type_text}"
    add_styled_paragraph(doc, info_text, size=10.5, bold=False)
    doc.add_paragraph("-" * 80)

    # 2. Executive Summary (For meeting, this is the Overview)
    # å¯¹äºä¼šè®®æ¨¡å¼ï¼Œå¦‚æœ executive_summary ä¸ºç©ºï¼Œåˆ™è·³è¿‡
    summary = data.get('executive_summary', '')
    if summary:
        add_styled_paragraph(doc, exec_title, size=14, bold=True)
        add_styled_paragraph(doc, summary, size=11)

    # 3. Structured Analysis
    header_map = SECTION_HEADERS.get(mode, {}).get(lang_code, {})
    structured = data.get('structured_analysis', {})
    
    if structured:
        # ä¼šè®®æ¨¡å¼ä¸éœ€è¦ "Detailed Analysis" è¿™ç§å¤§æ ‡é¢˜ï¼Œç›´æ¥è¿›å…¥ subsections
        if mode != 'meeting':
            section_2_title = "2. è¯¦ç»†ç»´åº¦åˆ†æ" if lang_code == 'zh' else "2. Detailed Analysis"
            add_styled_paragraph(doc, section_2_title, size=14, bold=True)

        # å¼ºåˆ¶é¡ºåº
        key_order = []
        if mode == 'commercial':
            key_order = ['market_size', 'competition', 'sales_marketing', 'channel_access', 'trends']
        elif mode == 'clinical':
            key_order = ['clinical_value', 'adoption', 'competition', 'pain_points', 'expectations']
        elif mode == 'meeting':
            key_order = ['meeting_context', 'key_discussion', 'conclusions', 'action_items']

        for key in key_order:
            if key in structured:
                points = structured[key]
                display_title = header_map.get(key, key.title())
                add_styled_paragraph(doc, display_title, size=12, bold=True)
                
                if isinstance(points, list):
                    for point in points:
                        add_styled_paragraph(doc, point, size=11, is_bullet=True)
                else:
                    add_styled_paragraph(doc, str(points), size=11)

    # 4. Other Findings
    other_dims = data.get('other_dimensions', {})
    if other_dims:
        add_styled_paragraph(doc, other_title, size=14, bold=True)
        for k, v in other_dims.items():
            clean_k = clean_text(k)
            add_styled_paragraph(doc, clean_k, size=12, bold=True)
            if isinstance(v, list):
                for point in v:
                    add_styled_paragraph(doc, point, size=11, is_bullet=True)
            else:
                add_styled_paragraph(doc, str(v), size=11)

    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# --- æ ¸å¿ƒé€»è¾‘ç±» ---
class InterviewAnalyzer:
    def __init__(self, api_key):
        self.api_key = api_key
        try:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-3-pro-preview') 
        except Exception as e:
            st.error(f"API Error: {e}")

    def process_audio(self, audio_file_path):
        try:
            myfile = genai.upload_file(audio_file_path)
            with st.spinner("ğŸ§ Uploading & Processing Audio... / æ­£åœ¨ä¸Šä¼ å¹¶è§£æéŸ³é¢‘..."):
                while myfile.state.name == "PROCESSING":
                    time.sleep(2)
                    myfile = genai.get_file(myfile.name)
            if myfile.state.name == "FAILED":
                st.error("Audio processing failed.")
                return None
            return myfile
        except Exception as e:
            st.error(f"Upload Error: {e}")
            return None

    def analyze_interview(self, audio_resource, mode):
        # æ¡†æ¶å®šä¹‰
        if mode == "commercial":
            keys_instruction = """
            Use these EXACT keys for `structured_analysis`:
            - `market_size` (for Market Size & Scale)
            - `competition` (for Competition Landscape)
            - `sales_marketing` (for Sales & Marketing)
            - `channel_access` (for Channel & Access)
            - `trends` (for Industry Trends)
            """
            framework_desc = """
            1. Market Size & Scale: Numbers, volume, revenue. (LOGIC FORMULA REQUIRED).
            2. Competition Landscape: Shares, strengths, weaknesses.
            3. Sales & Marketing: Pricing, promotion.
            4. Channel & Access: Distributors, admission.
            5. Industry Trends: Policy, macro environment.
            """
        elif mode == "clinical":
            keys_instruction = """
            Use these EXACT keys for `structured_analysis`:
            - `clinical_value` (for Clinical Value)
            - `adoption` (for Adoption & Usage)
            - `competition` (for Competitive Comparison)
            - `pain_points` (for Unmet Needs)
            - `expectations` (for Future Expectations)
            """
            framework_desc = """
            1. Clinical Value: Efficacy, safety.
            2. Adoption & Usage: Procedure volume, indications.
            3. Competitive Comparison: Brand vs Brand.
            4. Unmet Needs: Pain points.
            5. Future Expectations: Next-gen features.
            """
        else: # meeting
            keys_instruction = """
            Use these EXACT keys for `structured_analysis`:
            - `meeting_context` (Attendees, Background)
            - `key_discussion` (Detailed discussion points, arguments made)
            - `conclusions` (What was agreed or decided)
            - `action_items` (Follow-ups, To-dos with owners)
            """
            framework_desc = """
            1. Meeting Context: List attendees and the main purpose of the meeting.
            2. Key Discussion Points: COMPREHENSIVE summary of all topics discussed. Do not miss details.
            3. Conclusions & Decisions: Clear list of decisions made.
            4. Action Items: Specific next steps, who is responsible, and deadlines if mentioned.
            """

        system_prompt = f"""
        You are a **Senior Consultant** at Clearstate.
        Task: Create a rigorous, data-driven report based on the audio.

        ### ğŸš¨ CRITICAL INSTRUCTIONS:
        1.  **LANGUAGE CONSISTENCY**: Detect the language. 
            - If Chinese: Output ALL content in Simplified Chinese.
            - If English: Output ALL content in English.
            - **Set the `language` field in JSON to "zh" or "en".**
        2.  **NO MARKDOWN**: Do NOT use bolding marks (like **text**) in the JSON values. Output plain text only.
        3.  **STRICTLY NO TRANSLATION OF NAMES**: 
            - **KEEP IT VERBATIM**. 
            - Do NOT translate proper nouns (Company names, Product names, Technical terms).
            - Do not add parenthetical translations.
        4.  **COMPREHENSIVENESS**: 
            - For Interviews: Capture every number and logic.
            - For Meetings: **Do not omit any discussion points or follow-ups.** Be very detailed.

        ### FRAMEWORK KEYS:
        {keys_instruction}

        ### FRAMEWORK DETAILS:
        {framework_desc}

        ### OUTPUT JSON:
        {{
            "language": "zh", 
            "executive_summary": "High-level summary...",
            "structured_analysis": {{
                "key_1": ["Point 1", "Point 2"]
            }},
            "other_dimensions": {{
                "Topic": ["Detail"]
            }}
        }}
        """
        
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        try:
            response = self.model.generate_content(
                [audio_resource, system_prompt],
                safety_settings=safety_settings,
                request_options={"timeout": 600}
            )
            
            try:
                text = response.text
                if "```json" in text:
                    text = text.replace("```json", "").replace("```", "")
                return json.loads(text.strip())
            except ValueError:
                st.error("Error: Model output was not valid JSON.")
                return None

        except Exception as e:
            st.error(f"Analysis Interrupted: {e}")
            return None

# --- UI ä¸»ç¨‹åº ---
with st.sidebar:
    st.title("Clearstate AI")
    st.caption("Intelligent Qualitative Interview System")
    
    st.markdown("""
    <div class='developer-credit'>
    Developed by <b>Steve Jiang</b><br>
    Clearstate Consulting
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    api_key = st.text_input("Gemini API Key", type="password")
    
    st.markdown("### ğŸ“ Project Info / é¡¹ç›®ä¿¡æ¯")
    company_name = st.text_input("Company / å…¬å¸åç§°", placeholder="e.g. Medtronic")
    product_name = st.text_input("Product / äº§å“é¢†åŸŸ", placeholder="e.g. Stapler")
    interview_date = st.date_input("Date / è®¿è°ˆæ—¥æœŸ", datetime.date.today())
    
    st.markdown("### ğŸ› ï¸ Interviewee Type / è®¿è°ˆå¯¹è±¡ç±»å‹")
    
    # æ˜ å°„ UI æ˜¾ç¤ºåç§°
    def format_mode(option):
        if option == "commercial":
            return "ğŸ­ Trade (å•†ä¸š/å‚å•†)"
        elif option == "clinical":
            return "ğŸ‘¨â€âš•ï¸ Clinical (ä¸´åºŠ/ä¸“å®¶)"
        elif option == "meeting":
            return "ğŸ¤ Meeting (ä¼šè®®çºªè¦)"
        return option

    interview_mode = st.radio(
        "Select Type / é€‰æ‹©ç±»å‹",
        ("commercial", "clinical", "meeting"),
        format_func=format_mode
    )
    
    if st.button("ğŸ—‘ï¸ Reset / é‡ç½®"):
        st.session_state['analysis_result'] = None
        st.rerun()

st.markdown('<div class="main-header">æ™ºèƒ½å®šæ€§è®¿è°ˆæŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Intelligent Qualitative Interview Report Generation System</div>', unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“‚ Upload Audio / ä¸Šä¼ å½•éŸ³ (MP3/M4A Recommended)", type=['mp3', 'wav', 'm4a'])

if uploaded_file and st.session_state['analysis_result'] is None:
    if not api_key:
        st.error("Please enter API Key in the sidebar. / è¯·åœ¨ä¾§è¾¹æ è¾“å…¥ API Keyã€‚")
    elif not company_name or not product_name:
        st.warning("Please fill in Company & Product info. / è¯·å¡«å†™å…¬å¸å’Œäº§å“ä¿¡æ¯ã€‚")
    else:
        st.audio(uploaded_file, format='audio/mp3')
        if st.button("ğŸš€ Start Analysis (Gemini 3 Pro)", type="primary"):
            analyzer = InterviewAnalyzer(api_key)
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name

            with st.status("ğŸ¤– AI is processing... / AI æ­£åœ¨å¤„ç†...", expanded=True) as status:
                st.write("ğŸ§ Uploading audio to Gemini... / æ­£åœ¨ä¸Šä¼ éŸ³é¢‘...")
                audio_resource = analyzer.process_audio(tmp_file_path)
                
                if audio_resource:
                    st.write("ğŸ§  Analyzing (Model: gemini-3-pro-preview)... / æ­£åœ¨åˆ†æ...")
                    result = analyzer.analyze_interview(audio_resource, interview_mode)
                    
                    if result:
                        st.session_state['analysis_result'] = result
                        status.update(label="âœ… Done! / å®Œæˆï¼", state="complete", expanded=False)
                        os.remove(tmp_file_path)
                        st.rerun()

if st.session_state['analysis_result']:
    res = st.session_state['analysis_result']
    
    st.success("âœ… Analysis Complete. Please download the report. / åˆ†æå®Œæˆï¼Œè¯·ä¸‹è½½æŠ¥å‘Šã€‚")
    
    file_date_str = interview_date.strftime("%Y%m%d")
    file_name = f"Report_{company_name}_{product_name}_{file_date_str}.docx"
    
    docx_file = generate_word_report(res, company_name, product_name, interview_date, interview_mode)
    
    st.download_button(
        label=f"ğŸ“¥ Download Word Report / ä¸‹è½½ Word æŠ¥å‘Š",
        data=docx_file,
        file_name=file_name,
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        type="primary"
    )

    st.markdown("---")
    st.markdown("### ğŸ“Š Preview / é¢„è§ˆ")
    st.write(res.get('executive_summary'))
